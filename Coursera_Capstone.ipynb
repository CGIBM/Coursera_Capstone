{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# IBM Data Science Professional Certificate - Capstone Project"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1. Introduction\n### 1.1 Background\nWhile a reduction in number has been observed over the last decades, car accidents are still counted in thousands in Switzerland in 2020. Because the direct and indirect consequences of such events (injuries, death, psychological damages, material damages, etc.) are sizeable, there is value in identifying what are the causes of the accidents so that adequate prevention measures can be put in place. Moreover, it would be valuable to society - not the least from a resource planning standpoint - to understand when accidents are most likely to occur, and respectively what outcome severity (light injuries, severe injuries, fatal outcome) can be expected depending on when and under what circumstances the accident took place. Since 1992, the Swiss Federal Statistics Office (OFS) is collecting data on car accidents country-wide and making such information available to the public. This analysis will leverage this data. \n\n### 1.2 Problem\nThe objective is to explore a 2010-2019 dataset from the Swiss Federal Statistics Office (OFS) and determine what are the **key factors** that drive the **outcome** of an accident for the involved car(s)' passengers: light injuries, severe injuries, fatal outcome. Additionally, the outcomes of this analysis can be used as a prescriptive tool to :\n(1) Have the appropriate medical emergency resources allocated for the times, locations and circumstances when accidents are most likely to occur, with a particular emphasis on the severe and life-threatening cases. \n(2) Design prevention measures based on those accident factors identified as having the largest influence on accident outcomes. \n\n### 1.3 Interest\nBy being able to allocate medical emergency resources more efficiently and by being able to reduce injuries and deaths through prevention campaigns, society as a whole will reduce the economic impact of road hazards. This analysis is therefore aimed at decision-makers of the Swiss Confederation, notably those in charge of Transportation and Medical Affairs. Beyond economic considerations, there is also a moral value in reducing the suffering and deaths of the thousands of people affected by road accidents. \n\n## 2. Data Sources and Cleaning\n### 2.1 Data Sources\nThe dataset used here is defined as \"Road accidents where at least one of the parties was injured or worse\". As a result, this dataset does not report on material damages or other consequences than bodily injuries. It is also worth noting that this dataset does not distinguish between what exact type of vehicle was involved, whether a car, bicycle, motorcycle, tractor, pedestrian, skater, etc. \nThe dataset used in this analysis was obtained from the website of the Swiss Federal Statistics Office (OFS). A data browser allows the user to select the dimensions and time range of interest, within the limits of the Office's data structure. The extracted time range is the years 2010-2019. No other data source was used. \n\n**The variables in this dataset are :**  \nTypes of accidents : TYPE_ACCIDENT  \nType of road: TYPE_ROAD  \nSeverity of the accident: SEVERITY (the dependent variable)  \nMonth of the accident: MONTH  \nDay of the week: DAY  \nTime of the accident: TIME_ACCIDENT  \n  \nMore details are provided below:  \n  \n**Types of accidents**  \nSKID: The vehicle went into a skid/sideslid and/or the driver lost control of the car.  \nOVERTAKE : While trying to overtake or changing lanes. This also includes the variable state where the accident happened when the vehicle was returning to its original lane.   \nTURNING: While the vehicle was turning to change directions, ie. enter a new road.   \nINTERSECTION: Accident taking place at a crossroad or junction of two roads with the two implied vehicles staying on their respective roads.   \nBACK: The vehicle crashed into the back of another vehicle that was either mobile or immobile.  \nPARKING: While getting in or out of a parking spot.   \nANIMAL: Accident created by an animal.   \nFRONTAL: Frontal collisions. \nPEDESTRIANS: Accidents involving one or several pedestrians.  \n  \n**Time of the accident**  \nNIGHT : Between midnight and 6am  \nMORNING: Between 6am and noon  \nAFTNOON: Between noon and 6pm  \nEVENING: Between 6pm and midnight  \n  \n**Severity of the accident**  \nLIGHT_INJURIES: Light injuries to at least one of the involved parties.   \nSEVERE_INJURIES: Severe injuries to at least one of the involved parties.   \nDEATH: Death of at least one of the involved parties.  \n  \n**Type of road**  \nHWY: Highways, semi-highways and similars. The speed limit is typically 120 km/h, respectively 100 km/h for the semis.  \nMAINROAD: Main road, where the speed limit is typically 80 km/h.  \nSCDRYROAD: Secondary road, typically narrower and with a speed limit of 80km/h maximum.  \nOTHERROAD: Other types of road, for instance private access roads or country paths.  \n  \n \n### 2.2 Data Cleaning\nData cleaning consisted first in the following basic steps :\n\n(1) Translating the labels from French to English. This was performed in Excel directly on the CSV file. \n\n(2) Shortening the labels, for easier coding purposes. This was performed in Excel directly on the CSV file. \n\n(3) Transforming the non-numerical classifiers into dummy variables usable by the Machine Learning model discussed below. This was performed in the Jupyter Notebook. \n\nThe data was extractable only in a form where each row represents a unique combination of explanatory variables (such as time, day of the week, type of road, etc.). There are then 10 columns corresponding to the years 2010-2019, where it is reported in each column how many accidents happened in the said year for the given set of explanatory variables of the row. \nBecause a time-evolution is not the primary concern of this analysis, it was decided to :\n\n(4) Focus the analysis on the period 2010-2019 (as opposed to using the full dataset tracing back to 1992), as it is most likely more representative of the current road conditions and car technology. This was performed in the Jupyter Notebook.\n\n(5) Eliminate the time dimension of the dataset by performing the following operation : Sum the number of accidents across the years 2010-2019. This was performed in the Jupyter Notebook.\n\n\n### 2.3 Feature Selection\nTo enable a simpler analysis and higher readability, certain variables were simplified as follows :\nTYPE_ROAD: Highways, semi-highways and highways with special features were grouped into a single \"Highway\" category. This was performed in Excel directly on the CSV file. \n\n\n## 3. Methodology\n### 3.1 Exploratory Data Analysis\n### 3.2 Machine Learning Approach\nDecision tree because need to classify. And also because non-numerical values.\n\n### 3.3 Code"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "could not convert string to float: 'SKID'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-26-9bacb45da3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#Fitting of the tree on the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mdrugTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_trainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Running a prediction on the test dataset using the trained calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'SKID'"
                    ]
                }
            ],
            "source": "# Importing modules\n\nimport numpy as np # Numpy\nimport pandas as pd # Pandas\nfrom sklearn.tree import DecisionTreeClassifier # Scikit Learn\n\n# Downloading the data in CSV format from a **raw** URL\n\nimport io\nimport requests\nurl=\"https://raw.githubusercontent.com/CGIBM/Coursera_Capstone/master/dataset.csv\"\ns=requests.get(url).content\n\n# Placing the data in a Pandas dataframe\nmy_data=pd.read_csv(io.StringIO(s.decode('utf-8')))\n# Displaying the first 5 rows\nmy_data[0:5]\n# Removing values from 1992 to 2009\nmy_data.drop(my_data.columns[[6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]],axis=1,inplace=True)\nmy_data[0:5]\n# Eliminating the time dimension by summing across years\noccu=my_data.iloc[:,6:16]\nsumoccu=occu.sum(axis=1)\ndel occu\nmy_data[\"OCCU\"]=sumoccu\nmy_data.drop(my_data.columns[[6,7,8,9,10,11,12,13,14,15]],axis=1,inplace=True)\n\n# Eliminating rows with zero occurences between 2010-2019\nmy_data.drop(my_data[my_data.OCCU < 1].index, inplace=True)\nnewdata = pd.DataFrame(columns=my_data.columns)\n\n# Itemizing the rows where occurence > 1\nfor x in range(10):\n    occs=my_data.iloc[x,6]\n    for n in range(occs):\n        newdata=newdata.append(my_data.iloc[x,:], sort=False, ignore_index=True)\n     \n    \n\n# Drop the column containing the number of occurences\nnewdata= newdata.drop(['OCCU'], axis=1)\n\n# Declaring the Feature Matrix X and removing column 1 which is the Y dependent variable \nX = newdata[['TYPE_ACCIDENT', 'MONTH', 'DAY', 'TIME_ACCIDENT', 'TYPE_ROAD']].values \nX[0:5]\n\n\n# here transform into dummies see below\n\n\n# Declaring the Y dependent variable vector\ny = newdata[\"SEVERITY\"]\ny[0:5]\n\n# Separation of the total dataset into a train and a test set\nfrom sklearn.model_selection import train_test_split\nX_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.25, random_state=3) # allowing a 25% partition to the test set\n\n# Creation of the tree\ndrugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n\n#Fitting of the tree on the training dataset\ndrugTree.fit(X_trainset,y_trainset)\n\n# Running a prediction on the test dataset using the trained calibration\npredTree = drugTree.predict(X_testset)\n\n# Computing the accuracy of the tree on the test set\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_testset, predTree))\n\n# Visualizing the tree\nfrom sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline \n\ndot_data = StringIO()\nfilename = \"drugtree.png\"\nfeatureNames = my_data.columns[0:5]\ntargetNames = my_data[\"Drug\"].unique().tolist()\nout=tree.export_graphviz(drugTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 4. Results\n\n## 5. Discussion of the Results\n\n## 6. Conclusion"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEVERITY</th>\n      <th>TYPE_ACCIDENT</th>\n      <th>MONTH</th>\n      <th>DAY</th>\n      <th>TIME_ACCIDENT</th>\n      <th>TYPE_ROAD</th>\n      <th>OCCU</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>MORNING</td>\n      <td>MAINROAD</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>MORNING</td>\n      <td>SCDRYROAD</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>AFTNOON</td>\n      <td>MAINROAD</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>EVENING</td>\n      <td>HWY</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>EVENING</td>\n      <td>MAINROAD</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>EVENING</td>\n      <td>SCDRYROAD</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>TUE</td>\n      <td>MORNING</td>\n      <td>SCDRYROAD</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>TUE</td>\n      <td>AFTNOON</td>\n      <td>MAINROAD</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>TUE</td>\n      <td>AFTNOON</td>\n      <td>SCDRYROAD</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>TUE</td>\n      <td>EVENING</td>\n      <td>MAINROAD</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   SEVERITY TYPE_ACCIDENT MONTH  DAY TIME_ACCIDENT  TYPE_ROAD  OCCU\n8     DEATH          SKID   JAN  MON       MORNING   MAINROAD     3\n9     DEATH          SKID   JAN  MON       MORNING  SCDRYROAD     2\n14    DEATH          SKID   JAN  MON       AFTNOON   MAINROAD     1\n18    DEATH          SKID   JAN  MON       EVENING        HWY     1\n20    DEATH          SKID   JAN  MON       EVENING   MAINROAD     1\n21    DEATH          SKID   JAN  MON       EVENING  SCDRYROAD     1\n33    DEATH          SKID   JAN  TUE       MORNING  SCDRYROAD     2\n38    DEATH          SKID   JAN  TUE       AFTNOON   MAINROAD     1\n39    DEATH          SKID   JAN  TUE       AFTNOON  SCDRYROAD     2\n44    DEATH          SKID   JAN  TUE       EVENING   MAINROAD     2"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "my_data[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'occu' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-25-d65e53a8b62d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moccu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m: name 'occu' is not defined"
                    ]
                }
            ],
            "source": "occu[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0     0\n1     0\n2     0\n3     0\n4     0\n5     0\n6     0\n7     0\n8     3\n9     2\n10    0\n11    0\n12    0\n13    0\n14    1\n15    0\n16    0\n17    0\n18    1\n19    0\n20    1\n21    1\n22    0\n23    0\n24    0\n25    0\n26    0\n27    0\n28    0\n29    0\ndtype: int64"
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "sumoccu[0:30]"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "3"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "my_data.iloc[0,6]"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0\n1\n2\n3\n4\n5\n6\n"
                }
            ],
            "source": "astra=7\nfor x in range(astra):\n    print (x)"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEVERITY</th>\n      <th>TYPE_ACCIDENT</th>\n      <th>MONTH</th>\n      <th>DAY</th>\n      <th>TIME_ACCIDENT</th>\n      <th>TYPE_ROAD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>MORNING</td>\n      <td>MAINROAD</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>MORNING</td>\n      <td>MAINROAD</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>MORNING</td>\n      <td>MAINROAD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>MORNING</td>\n      <td>SCDRYROAD</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>MORNING</td>\n      <td>SCDRYROAD</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>AFTNOON</td>\n      <td>MAINROAD</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>EVENING</td>\n      <td>HWY</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>EVENING</td>\n      <td>MAINROAD</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>MON</td>\n      <td>EVENING</td>\n      <td>SCDRYROAD</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DEATH</td>\n      <td>SKID</td>\n      <td>JAN</td>\n      <td>TUE</td>\n      <td>MORNING</td>\n      <td>SCDRYROAD</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "  SEVERITY TYPE_ACCIDENT MONTH  DAY TIME_ACCIDENT  TYPE_ROAD\n0    DEATH          SKID   JAN  MON       MORNING   MAINROAD\n1    DEATH          SKID   JAN  MON       MORNING   MAINROAD\n2    DEATH          SKID   JAN  MON       MORNING   MAINROAD\n3    DEATH          SKID   JAN  MON       MORNING  SCDRYROAD\n4    DEATH          SKID   JAN  MON       MORNING  SCDRYROAD\n5    DEATH          SKID   JAN  MON       AFTNOON   MAINROAD\n6    DEATH          SKID   JAN  MON       EVENING        HWY\n7    DEATH          SKID   JAN  MON       EVENING   MAINROAD\n8    DEATH          SKID   JAN  MON       EVENING  SCDRYROAD\n9    DEATH          SKID   JAN  TUE       MORNING  SCDRYROAD"
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "newdata[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "SEVERITY            DEATH\nTYPE_ACCIDENT        SKID\nMONTH                 JAN\nDAY                   TUE\nTIME_ACCIDENT     EVENING\nTYPE_ROAD        MAINROAD\nOCCU                    2\nName: 44, dtype: object"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "my_data.iloc[x,:]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Transforming non-numerical classifiers into dummy variables ##### CHECK IF REALLY NECESSARY ******************************\nfrom sklearn import preprocessing\nle_sex = preprocessing.LabelEncoder()\nle_sex.fit(['F','M'])\nX[:,1] = le_sex.transform(X[:,1]) \n\n\nle_BP = preprocessing.LabelEncoder()\nle_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\nX[:,2] = le_BP.transform(X[:,2])\n\n\nle_Chol = preprocessing.LabelEncoder()\nle_Chol.fit([ 'NORMAL', 'HIGH'])\nX[:,3] = le_Chol.transform(X[:,3]) \n\nX[0:5]"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}