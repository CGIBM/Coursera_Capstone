{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# IBM Data Science Professional Certificate - Capstone Project"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1. Introduction\n### 1.1 Background\nWhile a reduction in number has been observed over the last decades, car accidents are still counted in thousands in Switzerland in 2020. Because the direct and indirect consequences of such events (injuries, death, psychological damages, material damages, etc.) are sizeable, there is value in identifying what are the causes of the accidents so that adequate prevention measures can be put in place. Moreover, it would be valuable to society - not the least from a resource planning standpoint - to understand when accidents are most likely to occur, and respectively what outcome severity (light injuries, heavy injuries, fatal outcome) can be expected depending on when and under what circumstances the accident took place. Since 1992, the Swiss Federal Statistics Office (OFS) is collecting data on car accidents country-wide and making such information available to the public. This analysis will leverage this data. \n\n### 1.2 Problem\nThe objective is to explore a 2010-2019 dataset from the Swiss Federal Statistics Office (OFS) and determine what are the **key factors** that drive the **outcome** of an accident for the involved car(s)' passengers: light injuries, heavy injuries, fatal outcome. Additionally, the outcomes of this analysis can be used as a prescriptive tool to :\n(1) Have the appropriate medical emergency resources allocated for the times, locations and circumstances when accidents are most likely to occur, with a particular emphasis on the severe and life-threatening cases. \n(2) Design prevention measures based on those drivers identified as having the largest influence on accident outcomes. \n\n### 1.3 Interest\nBy being able to allocate medical emergency resources more efficiently and by being able to reduce injuries and deaths through prevention campaigns, society as a whole will reduce the economic impact of road hazards. This analysis is therefore aimed at decision-makers of the Swiss Confederation, notably those in charge of Transportation and Medical Affairs. Beyond economic considerations, there is also a moral value in reducing the suffering and deaths of the thousands of people affected by road accidents. \n\n## 2. Data Sources and Cleaning\n### 2.1 Data Sources\nThe dataset used in this analysis was obtained from the website of the Swiss Federal Statistics Office (OFS). A data browser allows the user to select the dimensions and time range of interest, within the limits of the Office's data structure. The extracted time range is the years 2010-2019. No other data source was used. \n\n### 2.2 Data Cleaning\nData cleaning consisted first in the following basic steps :\n\n(1) Translating the labels from French to English. This was performed in Excel directly on the CSV file. \n\n(2) Shortening the labels, for easier coding purposes. This was performed in Excel directly on the CSV file. \n\n(3) Transforming the non-numerical classifiers into dummy variables usable by the Machine Learning model discussed below. This was performed in the Jupyter Notebook. \n\nThe data was extractable only in a form where each row represents a unique combination of explanatory variables (such as time, day of the week, type of road, etc.). There are then 10 columns corresponding to the years 2010-2019, where it is reported in each column how many accidents happened in the said year for the given set of explanatory variables of the row. \nBecause a time-evolution is not the primary concern of this analysis, it was decided to :\n\n(4) Focus the analysis on the period 2010-2019 (as opposed to using the full dataset tracing back to 1992), as it is most likely more representative of the current road conditions and car technology. This was performed in the Jupyter Notebook.\n\n(5) Eliminate the time dimension of the dataset by performing the following operation : Sum the number of accidents across the years 2010-2019. This was performed in the Jupyter Notebook.\n\n\n### 2.3 Feature Selection\nTo enable a simpler analysis and higher readability, certain variables were simplified as follows :\nTYPE_ROAD: Highways, semi-highways and highways with special features were grouped into a single \"Highway\" variable. This was performed in Excel directly on the CSV file. \n\n\n## 3. Methodology\n### 3.1 Exploratory Data Analysis\n### 3.2 Machine Learning Approach\nDecision tree because need to classify. And also because non-numerical values.\n\n### 3.3 Code"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Importing modules\n\nimport numpy as np # Numpy\nimport pandas as pd # Pandas\nfrom sklearn.tree import DecisionTreeClassifier # Scikit Learn\n\n# Downloading the data in CSV format\n\n# Placing the data in a Pandas dataframe\nmy_data = pd.read_csv(\"URL URL URL data.csv\", delimiter=\",\")\n# Displaying the first 5 rows\nmy_data[0:5]\n# Removing values from 1992 to 2009\n\nmy_data[0:5]\n# Eliminating the time dimension by summing across years\n\nmy_data[0:5]\n# Itemizing the rows where occurence > 1\n\nmy_data[0:5]\n# Declaring the Feature Matrix X and removing column 1 which is the Y dependent variable \nX = my_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values \nX[0:5]\n\n# Transforming non-numerical classifiers into dummy variables\nfrom sklearn import preprocessing\nle_sex = preprocessing.LabelEncoder()\nle_sex.fit(['F','M'])\nX[:,1] = le_sex.transform(X[:,1]) \n\n\nle_BP = preprocessing.LabelEncoder()\nle_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\nX[:,2] = le_BP.transform(X[:,2])\n\n\nle_Chol = preprocessing.LabelEncoder()\nle_Chol.fit([ 'NORMAL', 'HIGH'])\nX[:,3] = le_Chol.transform(X[:,3]) \n\nX[0:5]\n\n# Declaring the Y dependent variable vector\ny = my_data[\"Drug\"]\ny[0:5]\n\n# Separation of the total dataset into a train and a test set\nfrom sklearn.model_selection import train_test_split\nX_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.25, random_state=3) # allowing a 25% partition to the test set\n\n# Creation of the tree\ndrugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n\n#Fitting of the tree on the training dataset\ndrugTree.fit(X_trainset,y_trainset)\n\n# Running a prediction on the test dataset using the trained calibration\npredTree = drugTree.predict(X_testset)\n\n# Computing the accuracy of the tree on the test set\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_testset, predTree))\n\n# Visualizing the tree\nfrom sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline \n\ndot_data = StringIO()\nfilename = \"drugtree.png\"\nfeatureNames = my_data.columns[0:5]\ntargetNames = my_data[\"Drug\"].unique().tolist()\nout=tree.export_graphviz(drugTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 4. Results\n\n## 5. Discussion of the Results\n\n## 6. Conclusion"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}